{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skorch in /opt/conda/lib/python3.6/site-packages (0.8.0)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from skorch) (1.2.1)\r\n",
      "Requirement already satisfied: tqdm>=4.14.0 in /opt/conda/lib/python3.6/site-packages (from skorch) (4.32.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from skorch) (0.21.2)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from skorch) (1.16.4)\r\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.6/site-packages/tabulate-0.8.3-py3.6.egg (from skorch) (0.8.3)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.19.1->skorch) (0.13.2)\r\n"
     ]
    }
   ],
   "source": [
    "# Установка необходимых модулей\n",
    "!pip install skorch\n",
    "\n",
    "# Импорт модулей\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "import random\n",
    "import shutil \n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms, models\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.helper import predefined_split\n",
    "from skorch.helper import SliceDataset\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зафиксируем ГСЧ\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After zip extraction:\n",
      "['plates', '__notebook_source__.ipynb', '__MACOSX', '.ipynb_checkpoints', 'submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# Выполним разархивацию файла\n",
    "with zipfile.ZipFile('../input/plates.zip', 'r') as zip_obj:\n",
    "    zip_obj.extractall('/kaggle/working/')\n",
    "    \n",
    "print('After zip extraction:')\n",
    "print(os.listdir(\"/kaggle/working/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'train', 'test']\n"
     ]
    }
   ],
   "source": [
    "# Выполним проверку правильности разархивации\n",
    "data_root = '/kaggle/working/plates/'\n",
    "print(os.listdir(data_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 3796.08it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 3926.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Создадим папку для тренировочного набора данных\n",
    "train_dir = 'train'\n",
    "class_names = ['cleaned', 'dirty']\n",
    "\n",
    "for class_name in class_names:\n",
    "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "\n",
    "# Поместим изображения в папку\n",
    "for class_name in class_names:\n",
    "    source_dir = os.path.join(data_root, 'train', class_name)\n",
    "    for i, file_name in enumerate(tqdm(os.listdir(source_dir))):\n",
    "        dest_dir = os.path.join(train_dir, class_name) \n",
    "        shutil.copy(os.path.join(source_dir, file_name), \n",
    "                    os.path.join(dest_dir, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим преобразования, которые будут выполнены над изображениями\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.5,\n",
    "            contrast=0.5,\n",
    "            saturation=0.5,\n",
    "            hue=0.5\n",
    "        )\n",
    "    ]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Создадим датасет с изображениями\n",
    "train_dataset = torch.utils.data.ConcatDataset([\n",
    "    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n",
    "    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n",
    "    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n",
    "    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n",
    "    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n",
    "    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n",
    "    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n",
    "    torchvision.datasets.ImageFolder(train_dir, train_transforms)\n",
    "])\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, \n",
    "    shuffle=True, num_workers=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Класс полносвязной сети для выходного слоя \n",
    "    class ModelNet(torch.nn.Module):\n",
    "        def __init__(self, n_neurons):\n",
    "            super(ModelNet, self).__init__()\n",
    "            self.fc1 = torch.nn.Linear(n_neurons, 128)\n",
    "            self.act1 =  torch.nn.ReLU()\n",
    "            self.fc2 = torch.nn.Linear(128, 128)\n",
    "            self.act2 = torch.nn.ReLU()\n",
    "            self.fc3 = torch.nn.Linear(128, 2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.fc1(x)\n",
    "            x = self.act1(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.act2(x)\n",
    "            x = self.fc3(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, возвращающая модель нейронной сети\n",
    "def set_model():\n",
    "    '''\n",
    "    This function creates model: resnet152 + 3 fc-layers\n",
    "    '''\n",
    "    model = models.resnet152(pretrained=True)\n",
    "    # Включим расчет градиента для всех уровней\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    model.fc = ModelNet(model.fc.in_features)\n",
    "    return model\n",
    "\n",
    "model = set_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуем уменьшение шага градиентного спуска\n",
    "lrscheduler = LRScheduler(policy='StepLR', step_size=3, gamma=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим начальные параметры модели\n",
    "net = NeuralNetClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    batch_size=batch_size,\n",
    "    train_split=None,\n",
    "    device='cuda',\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__num_workers=8,\n",
    "    callbacks=[lrscheduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведем данные к удобному для работы формату\n",
    "X_sl = SliceDataset(train_dataset)\n",
    "y_sl = SliceDataset(train_dataset, idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.6800\u001b[0m  10.5988\n",
      "      2        \u001b[36m0.6404\u001b[0m  9.1801\n",
      "      3        \u001b[36m0.5743\u001b[0m  9.3180\n",
      "      4        \u001b[36m0.4838\u001b[0m  9.0470\n",
      "      5        \u001b[36m0.3755\u001b[0m  9.0978\n",
      "      6        \u001b[36m0.3023\u001b[0m  9.2663\n",
      "      7        \u001b[36m0.2703\u001b[0m  10.3296\n",
      "      8        \u001b[36m0.2514\u001b[0m  9.3957\n",
      "      9        \u001b[36m0.2513\u001b[0m  9.1429\n",
      "     10        \u001b[36m0.2257\u001b[0m  9.0607\n",
      "     11        \u001b[36m0.1837\u001b[0m  9.0313\n",
      "     12        0.2029  8.8795\n",
      "     13        \u001b[36m0.1673\u001b[0m  9.4864\n",
      "     14        \u001b[36m0.1599\u001b[0m  10.0441\n",
      "     15        0.1770  9.2353\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6813\u001b[0m  9.3344\n",
      "      2        \u001b[36m0.6417\u001b[0m  9.2496\n",
      "      3        \u001b[36m0.5702\u001b[0m  9.2981\n",
      "      4        \u001b[36m0.4550\u001b[0m  9.5212\n",
      "      5        \u001b[36m0.3717\u001b[0m  9.4573\n",
      "      6        \u001b[36m0.3297\u001b[0m  9.3894\n",
      "      7        \u001b[36m0.2593\u001b[0m  9.1298\n",
      "      8        \u001b[36m0.2422\u001b[0m  9.2067\n",
      "      9        \u001b[36m0.2266\u001b[0m  9.0818\n",
      "     10        0.2357  9.5389\n",
      "     11        \u001b[36m0.2053\u001b[0m  9.4636\n",
      "     12        \u001b[36m0.1953\u001b[0m  9.3363\n",
      "     13        0.2201  9.1346\n",
      "     14        \u001b[36m0.1718\u001b[0m  9.1201\n",
      "     15        0.1938  9.0905\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6818\u001b[0m  9.4599\n",
      "      2        \u001b[36m0.6500\u001b[0m  9.2468\n",
      "      3        \u001b[36m0.5796\u001b[0m  9.2156\n",
      "      4        \u001b[36m0.4864\u001b[0m  9.1451\n",
      "      5        \u001b[36m0.3886\u001b[0m  9.1539\n",
      "      6        \u001b[36m0.3266\u001b[0m  9.0566\n",
      "      7        \u001b[36m0.3254\u001b[0m  10.1694\n",
      "      8        \u001b[36m0.2466\u001b[0m  9.1848\n",
      "      9        \u001b[36m0.2087\u001b[0m  9.3080\n",
      "     10        \u001b[36m0.1882\u001b[0m  9.6556\n",
      "     11        \u001b[36m0.1717\u001b[0m  9.1216\n",
      "     12        0.2099  8.9954\n",
      "     13        0.1758  9.5882\n",
      "     14        0.2265  9.5256\n",
      "     15        0.1900  9.0155\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6844\u001b[0m  9.6477\n",
      "      2        \u001b[36m0.6443\u001b[0m  9.0055\n",
      "      3        \u001b[36m0.5834\u001b[0m  9.1896\n",
      "      4        \u001b[36m0.4860\u001b[0m  9.6562\n",
      "      5        \u001b[36m0.3949\u001b[0m  8.9906\n",
      "      6        \u001b[36m0.3573\u001b[0m  9.0397\n",
      "      7        \u001b[36m0.2616\u001b[0m  9.3523\n",
      "      8        \u001b[36m0.2599\u001b[0m  9.2464\n",
      "      9        \u001b[36m0.2323\u001b[0m  9.1708\n",
      "     10        0.2524  9.4617\n",
      "     11        \u001b[36m0.2017\u001b[0m  9.1928\n",
      "     12        \u001b[36m0.1941\u001b[0m  9.0852\n",
      "     13        \u001b[36m0.1741\u001b[0m  9.1974\n",
      "     14        0.1892  8.9774\n",
      "     15        0.1890  9.1262\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6790\u001b[0m  9.6883\n",
      "      2        \u001b[36m0.6397\u001b[0m  9.0026\n",
      "      3        \u001b[36m0.5605\u001b[0m  9.1236\n",
      "      4        \u001b[36m0.4653\u001b[0m  9.2331\n",
      "      5        \u001b[36m0.3678\u001b[0m  9.1631\n",
      "      6        \u001b[36m0.3142\u001b[0m  9.1343\n",
      "      7        \u001b[36m0.2732\u001b[0m  9.6477\n",
      "      8        \u001b[36m0.2579\u001b[0m  9.5271\n",
      "      9        \u001b[36m0.2353\u001b[0m  8.9784\n",
      "     10        \u001b[36m0.2313\u001b[0m  9.3933\n",
      "     11        \u001b[36m0.1708\u001b[0m  9.2956\n",
      "     12        0.1964  9.1113\n",
      "     13        0.1917  9.5579\n",
      "     14        0.2007  9.5343\n",
      "     15        0.1740  8.9725\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6823\u001b[0m  9.6491\n",
      "      2        \u001b[36m0.6451\u001b[0m  9.2268\n",
      "      3        \u001b[36m0.5861\u001b[0m  9.4042\n",
      "      4        \u001b[36m0.4784\u001b[0m  9.7032\n",
      "      5        \u001b[36m0.3838\u001b[0m  9.3241\n",
      "      6        \u001b[36m0.3379\u001b[0m  9.0522\n",
      "      7        \u001b[36m0.2953\u001b[0m  9.0665\n",
      "      8        \u001b[36m0.2569\u001b[0m  9.5241\n",
      "      9        \u001b[36m0.2090\u001b[0m  9.3273\n",
      "     10        0.2090  9.9547\n",
      "     11        \u001b[36m0.1756\u001b[0m  9.2425\n",
      "     12        0.1874  9.1165\n",
      "     13        0.1987  9.0888\n",
      "     14        0.2078  9.2182\n",
      "     15        0.1869  9.4360\n",
      "     16        0.1832  9.6134\n",
      "     17        0.1852  9.6393\n",
      "     18        \u001b[36m0.1633\u001b[0m  9.1261\n",
      "     19        \u001b[36m0.1348\u001b[0m  8.9663\n",
      "     20        0.1492  9.0375\n",
      "     21        \u001b[36m0.1201\u001b[0m  9.3090\n",
      "     22        0.1663  9.2625\n",
      "     23        0.1827  9.9777\n",
      "     24        0.1535  9.0762\n",
      "     25        0.1526  9.2338\n",
      "     26        0.1702  9.0220\n",
      "     27        0.1567  9.0777\n",
      "     28        0.1451  9.4210\n",
      "     29        0.1612  9.7484\n",
      "     30        0.1401  9.2638\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6830\u001b[0m  9.0028\n",
      "      2        \u001b[36m0.6465\u001b[0m  9.0706\n",
      "      3        \u001b[36m0.5802\u001b[0m  9.0557\n",
      "      4        \u001b[36m0.4785\u001b[0m  9.3473\n",
      "      5        \u001b[36m0.3985\u001b[0m  10.2993\n",
      "      6        \u001b[36m0.3135\u001b[0m  9.2215\n",
      "      7        \u001b[36m0.2885\u001b[0m  9.2508\n",
      "      8        \u001b[36m0.2599\u001b[0m  9.1016\n",
      "      9        \u001b[36m0.2240\u001b[0m  9.1226\n",
      "     10        \u001b[36m0.2152\u001b[0m  9.0469\n",
      "     11        0.2184  9.8664\n",
      "     12        \u001b[36m0.1914\u001b[0m  9.4268\n",
      "     13        \u001b[36m0.1603\u001b[0m  9.1789\n",
      "     14        0.1948  9.0369\n",
      "     15        0.1614  9.1340\n",
      "     16        0.1772  9.2786\n",
      "     17        0.1645  9.3638\n",
      "     18        0.1651  9.7863\n",
      "     19        \u001b[36m0.1527\u001b[0m  9.6468\n",
      "     20        0.1939  9.1624\n",
      "     21        0.1910  9.0489\n",
      "     22        0.1549  8.9871\n",
      "     23        \u001b[36m0.1380\u001b[0m  9.4390\n",
      "     24        0.1455  9.9080\n",
      "     25        0.1528  9.0744\n",
      "     26        0.1691  9.1363\n",
      "     27        0.1839  9.0041\n",
      "     28        0.1812  9.2416\n",
      "     29        0.1446  8.9303\n",
      "     30        0.1408  9.5909\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6784\u001b[0m  9.2888\n",
      "      2        \u001b[36m0.6366\u001b[0m  9.2941\n",
      "      3        \u001b[36m0.5526\u001b[0m  9.1592\n",
      "      4        \u001b[36m0.4444\u001b[0m  9.2751\n",
      "      5        \u001b[36m0.3571\u001b[0m  8.9817\n",
      "      6        \u001b[36m0.3035\u001b[0m  10.5075\n",
      "      7        \u001b[36m0.2426\u001b[0m  9.3671\n",
      "      8        \u001b[36m0.2311\u001b[0m  9.1244\n",
      "      9        0.2394  9.3057\n",
      "     10        \u001b[36m0.1958\u001b[0m  9.1070\n",
      "     11        0.2215  9.1046\n",
      "     12        0.1963  9.3146\n",
      "     13        0.2063  10.1077\n",
      "     14        \u001b[36m0.1497\u001b[0m  9.2424\n",
      "     15        0.1613  9.2856\n",
      "     16        0.1554  9.1849\n",
      "     17        0.1727  9.0396\n",
      "     18        0.2046  9.2097\n",
      "     19        0.1499  9.8815\n",
      "     20        0.1853  9.4637\n",
      "     21        0.1740  9.2777\n",
      "     22        0.1834  9.1571\n",
      "     23        \u001b[36m0.1382\u001b[0m  9.0463\n",
      "     24        0.1512  9.0454\n",
      "     25        0.1641  9.6399\n",
      "     26        0.1448  9.3158\n",
      "     27        \u001b[36m0.1220\u001b[0m  9.3278\n",
      "     28        0.1527  9.1385\n",
      "     29        0.1362  9.0541\n",
      "     30        0.1436  9.0830\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6833\u001b[0m  9.6199\n",
      "      2        \u001b[36m0.6459\u001b[0m  9.4308\n",
      "      3        \u001b[36m0.5734\u001b[0m  9.4233\n",
      "      4        \u001b[36m0.4773\u001b[0m  9.1472\n",
      "      5        \u001b[36m0.3930\u001b[0m  9.2623\n",
      "      6        \u001b[36m0.3159\u001b[0m  9.0791\n",
      "      7        \u001b[36m0.2767\u001b[0m  10.1918\n",
      "      8        \u001b[36m0.2229\u001b[0m  9.0718\n",
      "      9        0.2345  9.2091\n",
      "     10        \u001b[36m0.2011\u001b[0m  9.6338\n",
      "     11        \u001b[36m0.1768\u001b[0m  9.0637\n",
      "     12        0.1935  9.1787\n",
      "     13        0.1801  9.6849\n",
      "     14        \u001b[36m0.1669\u001b[0m  9.1883\n",
      "     15        0.1699  8.9226\n",
      "     16        0.1881  9.3104\n",
      "     17        0.1858  9.3394\n",
      "     18        \u001b[36m0.1507\u001b[0m  8.9630\n",
      "     19        \u001b[36m0.1367\u001b[0m  9.0541\n",
      "     20        0.1442  9.8674\n",
      "     21        0.1683  9.3115\n",
      "     22        \u001b[36m0.1260\u001b[0m  9.2321\n",
      "     23        0.1501  9.1878\n",
      "     24        0.1378  9.3178\n",
      "     25        0.1474  9.1502\n",
      "     26        0.1761  9.6268\n",
      "     27        0.1513  9.2915\n",
      "     28        0.1622  9.2394\n",
      "     29        0.1799  9.1557\n",
      "     30        0.1280  9.3651\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6786\u001b[0m  9.4930\n",
      "      2        \u001b[36m0.6411\u001b[0m  9.5457\n",
      "      3        \u001b[36m0.5679\u001b[0m  9.0242\n",
      "      4        \u001b[36m0.4485\u001b[0m  9.2170\n",
      "      5        \u001b[36m0.3737\u001b[0m  9.4205\n",
      "      6        \u001b[36m0.3281\u001b[0m  9.0103\n",
      "      7        \u001b[36m0.2784\u001b[0m  9.3087\n",
      "      8        \u001b[36m0.2433\u001b[0m  9.6491\n",
      "      9        \u001b[36m0.2341\u001b[0m  9.2619\n",
      "     10        \u001b[36m0.2218\u001b[0m  9.0011\n",
      "     11        \u001b[36m0.1880\u001b[0m  9.4858\n",
      "     12        0.2185  9.2082\n",
      "     13        \u001b[36m0.1835\u001b[0m  9.2434\n",
      "     14        0.2126  9.4703\n",
      "     15        \u001b[36m0.1630\u001b[0m  9.5149\n",
      "     16        \u001b[36m0.1612\u001b[0m  9.0084\n",
      "     17        \u001b[36m0.1604\u001b[0m  9.0324\n",
      "     18        0.1707  9.3645\n",
      "     19        0.1882  9.1737\n",
      "     20        \u001b[36m0.1556\u001b[0m  9.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     21        \u001b[36m0.1479\u001b[0m  9.7548\n",
      "     22        \u001b[36m0.1458\u001b[0m  9.1523\n",
      "     23        0.1546  9.1168\n",
      "     24        0.1628  9.4175\n",
      "     25        0.1621  9.3487\n",
      "     26        \u001b[36m0.1375\u001b[0m  9.1127\n",
      "     27        0.1476  9.5716\n",
      "     28        0.1476  9.7944\n",
      "     29        0.1850  8.8893\n",
      "     30        0.1496  9.0548\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5075\u001b[0m  9.4320\n",
      "      2        \u001b[36m0.2427\u001b[0m  9.3408\n",
      "      3        0.3709  9.6212\n",
      "      4        0.3280  9.1464\n",
      "      5        \u001b[36m0.2320\u001b[0m  9.1850\n",
      "      6        \u001b[36m0.1159\u001b[0m  8.9512\n",
      "      7        0.1846  9.3026\n",
      "      8        0.1171  9.2537\n",
      "      9        0.2206  9.7712\n",
      "     10        \u001b[36m0.1057\u001b[0m  9.0191\n",
      "     11        0.1115  9.0168\n",
      "     12        0.1236  9.0551\n",
      "     13        \u001b[36m0.0669\u001b[0m  9.1375\n",
      "     14        \u001b[36m0.0618\u001b[0m  9.0518\n",
      "     15        0.0994  9.1722\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5402\u001b[0m  8.9716\n",
      "      2        \u001b[36m0.2758\u001b[0m  9.2387\n",
      "      3        \u001b[36m0.2599\u001b[0m  9.3138\n",
      "      4        \u001b[36m0.2296\u001b[0m  9.3399\n",
      "      5        0.3154  9.2946\n",
      "      6        0.3054  9.9658\n",
      "      7        \u001b[36m0.1640\u001b[0m  9.1824\n",
      "      8        \u001b[36m0.1118\u001b[0m  9.1432\n",
      "      9        0.1766  9.1146\n",
      "     10        0.1134  9.0429\n",
      "     11        0.2009  9.3169\n",
      "     12        \u001b[36m0.0770\u001b[0m  9.4261\n",
      "     13        0.1112  9.2941\n",
      "     14        0.0833  9.2011\n",
      "     15        0.1115  8.9586\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4861\u001b[0m  9.4843\n",
      "      2        \u001b[36m0.3252\u001b[0m  9.2869\n",
      "      3        0.3378  9.8488\n",
      "      4        \u001b[36m0.2756\u001b[0m  9.3205\n",
      "      5        \u001b[36m0.1419\u001b[0m  8.8904\n",
      "      6        0.2094  9.1961\n",
      "      7        0.1929  8.9364\n",
      "      8        \u001b[36m0.1330\u001b[0m  9.2625\n",
      "      9        \u001b[36m0.0581\u001b[0m  9.8520\n",
      "     10        0.0854  9.3077\n",
      "     11        0.0904  9.0213\n",
      "     12        \u001b[36m0.0436\u001b[0m  8.8850\n",
      "     13        0.1668  8.9920\n",
      "     14        0.0636  9.4628\n",
      "     15        0.0574  9.4615\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5137\u001b[0m  9.0844\n",
      "      2        \u001b[36m0.3482\u001b[0m  9.1660\n",
      "      3        \u001b[36m0.2394\u001b[0m  9.1846\n",
      "      4        \u001b[36m0.2231\u001b[0m  8.8898\n",
      "      5        \u001b[36m0.2013\u001b[0m  9.2330\n",
      "      6        0.2165  10.3952\n",
      "      7        \u001b[36m0.1472\u001b[0m  9.2144\n",
      "      8        \u001b[36m0.1382\u001b[0m  9.0574\n",
      "      9        0.2030  9.2333\n",
      "     10        \u001b[36m0.1084\u001b[0m  8.9844\n",
      "     11        0.1274  9.2292\n",
      "     12        \u001b[36m0.1047\u001b[0m  9.3751\n",
      "     13        \u001b[36m0.0681\u001b[0m  10.1387\n",
      "     14        0.1397  9.1411\n",
      "     15        0.0751  9.0412\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4960\u001b[0m  9.0169\n",
      "      2        \u001b[36m0.3553\u001b[0m  9.0395\n",
      "      3        \u001b[36m0.2610\u001b[0m  9.9913\n",
      "      4        \u001b[36m0.2005\u001b[0m  9.5027\n",
      "      5        0.2395  9.0798\n",
      "      6        0.2157  9.1546\n",
      "      7        \u001b[36m0.1417\u001b[0m  9.0217\n",
      "      8        0.1641  9.1093\n",
      "      9        0.1986  9.8400\n",
      "     10        \u001b[36m0.0935\u001b[0m  9.6505\n",
      "     11        \u001b[36m0.0818\u001b[0m  9.4232\n",
      "     12        0.1122  9.1830\n",
      "     13        \u001b[36m0.0809\u001b[0m  8.8641\n",
      "     14        0.0972  9.0637\n",
      "     15        0.1208  9.2721\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5352\u001b[0m  9.3403\n",
      "      2        \u001b[36m0.3414\u001b[0m  9.3154\n",
      "      3        \u001b[36m0.3298\u001b[0m  9.0065\n",
      "      4        \u001b[36m0.2537\u001b[0m  8.8270\n",
      "      5        \u001b[36m0.1905\u001b[0m  9.2325\n",
      "      6        \u001b[36m0.1508\u001b[0m  9.3478\n",
      "      7        \u001b[36m0.1450\u001b[0m  9.6729\n",
      "      8        0.2227  9.1602\n",
      "      9        0.1999  9.1701\n",
      "     10        \u001b[36m0.0988\u001b[0m  9.0057\n",
      "     11        \u001b[36m0.0953\u001b[0m  9.0085\n",
      "     12        0.1251  9.2194\n",
      "     13        0.1055  9.7935\n",
      "     14        \u001b[36m0.0620\u001b[0m  9.0444\n",
      "     15        0.1852  9.0894\n",
      "     16        0.0956  9.1656\n",
      "     17        0.0767  9.0521\n",
      "     18        0.1639  8.9470\n",
      "     19        0.0874  10.0350\n",
      "     20        0.1235  9.4787\n",
      "     21        0.1423  9.0524\n",
      "     22        \u001b[36m0.0583\u001b[0m  9.1116\n",
      "     23        \u001b[36m0.0502\u001b[0m  9.3631\n",
      "     24        0.0584  9.0518\n",
      "     25        \u001b[36m0.0449\u001b[0m  9.2217\n",
      "     26        0.0894  9.7607\n",
      "     27        0.0656  9.4202\n",
      "     28        0.0601  9.1510\n",
      "     29        0.0768  8.9337\n",
      "     30        \u001b[36m0.0308\u001b[0m  9.0860\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5174\u001b[0m  9.7436\n",
      "      2        \u001b[36m0.3542\u001b[0m  9.1987\n",
      "      3        \u001b[36m0.2711\u001b[0m  9.3511\n",
      "      4        \u001b[36m0.2156\u001b[0m  9.3084\n",
      "      5        0.2237  8.9909\n",
      "      6        \u001b[36m0.1147\u001b[0m  8.9215\n",
      "      7        0.2373  9.1524\n",
      "      8        0.1308  9.7916\n",
      "      9        \u001b[36m0.1034\u001b[0m  9.2203\n",
      "     10        0.1263  9.3009\n",
      "     11        \u001b[36m0.0780\u001b[0m  8.9671\n",
      "     12        \u001b[36m0.0739\u001b[0m  9.2854\n",
      "     13        0.0858  9.0491\n",
      "     14        \u001b[36m0.0665\u001b[0m  10.2678\n",
      "     15        \u001b[36m0.0646\u001b[0m  9.3576\n",
      "     16        \u001b[36m0.0540\u001b[0m  9.4845\n",
      "     17        \u001b[36m0.0478\u001b[0m  9.5397\n",
      "     18        \u001b[36m0.0402\u001b[0m  9.3105\n",
      "     19        0.0448  9.0652\n",
      "     20        \u001b[36m0.0351\u001b[0m  9.5904\n",
      "     21        0.0823  9.5927\n",
      "     22        0.0724  9.0307\n",
      "     23        0.0679  9.1738\n",
      "     24        \u001b[36m0.0318\u001b[0m  9.1386\n",
      "     25        0.0619  9.0806\n",
      "     26        0.0637  9.2587\n",
      "     27        0.0623  9.5053\n",
      "     28        \u001b[36m0.0295\u001b[0m  9.3584\n",
      "     29        0.0302  9.1942\n",
      "     30        0.0321  8.9553\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5302\u001b[0m  8.9206\n",
      "      2        \u001b[36m0.3366\u001b[0m  9.6791\n",
      "      3        \u001b[36m0.2509\u001b[0m  9.5051\n",
      "      4        \u001b[36m0.1954\u001b[0m  9.0489\n",
      "      5        0.2483  9.0930\n",
      "      6        \u001b[36m0.1326\u001b[0m  9.0153\n",
      "      7        0.1838  8.9760\n",
      "      8        0.1396  9.0420\n",
      "      9        0.1639  9.5073\n",
      "     10        0.1538  9.0837\n",
      "     11        \u001b[36m0.0944\u001b[0m  9.3579\n",
      "     12        0.1412  9.0450\n",
      "     13        0.1446  8.9349\n",
      "     14        0.1014  8.9423\n",
      "     15        \u001b[36m0.0599\u001b[0m  9.8546\n",
      "     16        0.0618  9.3908\n",
      "     17        0.0779  9.1849\n",
      "     18        0.1068  9.1327\n",
      "     19        0.1926  8.9369\n",
      "     20        \u001b[36m0.0445\u001b[0m  8.8215\n",
      "     21        0.0607  9.1282\n",
      "     22        0.0662  9.8599\n",
      "     23        0.0761  9.2686\n",
      "     24        0.0885  9.0572\n",
      "     25        0.0634  9.2480\n",
      "     26        0.0728  8.8312\n",
      "     27        \u001b[36m0.0413\u001b[0m  8.9776\n",
      "     28        0.0585  9.8758\n",
      "     29        0.0459  9.3801\n",
      "     30        \u001b[36m0.0395\u001b[0m  9.1314\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.5877\u001b[0m  9.1444\n",
      "      2        \u001b[36m0.3480\u001b[0m  9.0794\n",
      "      3        \u001b[36m0.2806\u001b[0m  9.3699\n",
      "      4        \u001b[36m0.2730\u001b[0m  9.5933\n",
      "      5        \u001b[36m0.2552\u001b[0m  9.3899\n",
      "      6        \u001b[36m0.1313\u001b[0m  9.1945\n",
      "      7        0.1658  8.9456\n",
      "      8        \u001b[36m0.1101\u001b[0m  9.1997\n",
      "      9        0.1389  9.1437\n",
      "     10        \u001b[36m0.0958\u001b[0m  9.8332\n",
      "     11        0.0983  9.3499\n",
      "     12        0.1294  9.5166\n",
      "     13        \u001b[36m0.0376\u001b[0m  9.1030\n",
      "     14        0.0422  9.0223\n",
      "     15        0.0579  8.9698\n",
      "     16        0.1401  9.1722\n",
      "     17        0.0657  9.9422\n",
      "     18        0.0862  9.1828\n",
      "     19        0.0982  9.3066\n",
      "     20        0.0825  9.1779\n",
      "     21        0.0884  9.0861\n",
      "     22        0.0658  8.9928\n",
      "     23        0.0411  10.2870\n",
      "     24        0.1015  9.3545\n",
      "     25        0.0911  9.0818\n",
      "     26        0.0643  9.2883\n",
      "     27        0.1038  9.0969\n",
      "     28        0.1687  8.9505\n",
      "     29        0.0993  9.6861\n",
      "     30        0.0608  9.8990\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.4959\u001b[0m  9.3082\n",
      "      2        \u001b[36m0.2865\u001b[0m  9.2619\n",
      "      3        0.3396  8.9928\n",
      "      4        \u001b[36m0.2539\u001b[0m  9.3748\n",
      "      5        \u001b[36m0.2366\u001b[0m  9.3879\n",
      "      6        \u001b[36m0.1655\u001b[0m  9.3572\n",
      "      7        0.1966  9.0970\n",
      "      8        0.2146  9.2035\n",
      "      9        \u001b[36m0.1295\u001b[0m  9.1527\n",
      "     10        \u001b[36m0.1258\u001b[0m  8.8980\n",
      "     11        \u001b[36m0.0683\u001b[0m  9.5847\n",
      "     12        0.1064  9.4111\n",
      "     13        0.1223  9.3617\n",
      "     14        0.1170  9.1899\n",
      "     15        \u001b[36m0.0557\u001b[0m  8.8631\n",
      "     16        0.0852  9.0067\n",
      "     17        0.0746  9.1189\n",
      "     18        \u001b[36m0.0522\u001b[0m  9.5057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19        0.1074  9.2765\n",
      "     20        0.0595  9.3139\n",
      "     21        \u001b[36m0.0364\u001b[0m  8.9909\n",
      "     22        0.0387  9.0304\n",
      "     23        0.0679  9.2051\n",
      "     24        0.0518  9.7237\n",
      "     25        0.0437  9.4032\n",
      "     26        0.0696  9.3497\n",
      "     27        0.0385  9.3618\n",
      "     28        0.1020  9.1168\n",
      "     29        0.0421  8.9835\n",
      "     30        0.0481  9.3444\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7012\u001b[0m  9.4690\n",
      "      2        0.7039  9.3050\n",
      "      3        \u001b[36m0.6984\u001b[0m  9.3536\n",
      "      4        0.6994  9.0848\n",
      "      5        \u001b[36m0.6976\u001b[0m  9.0150\n",
      "      6        \u001b[36m0.6938\u001b[0m  10.3485\n",
      "      7        0.6940  8.8905\n",
      "      8        \u001b[36m0.6883\u001b[0m  9.1922\n",
      "      9        0.6967  9.2261\n",
      "     10        0.6934  9.3291\n",
      "     11        0.6920  8.9410\n",
      "     12        0.6901  9.3289\n",
      "     13        0.6893  9.7017\n",
      "     14        \u001b[36m0.6857\u001b[0m  9.1256\n",
      "     15        \u001b[36m0.6778\u001b[0m  9.2129\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6985\u001b[0m  9.3370\n",
      "      2        0.7085  9.3410\n",
      "      3        0.6998  9.4480\n",
      "      4        \u001b[36m0.6942\u001b[0m  9.1111\n",
      "      5        0.6944  9.4006\n",
      "      6        \u001b[36m0.6859\u001b[0m  9.0795\n",
      "      7        0.7006  9.1995\n",
      "      8        0.6935  9.2165\n",
      "      9        0.6926  9.5682\n",
      "     10        0.6935  8.9858\n",
      "     11        0.6916  9.2325\n",
      "     12        0.6906  9.3911\n",
      "     13        0.6898  9.1073\n",
      "     14        0.6950  9.0501\n",
      "     15        0.6929  9.6504\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7216\u001b[0m  9.0092\n",
      "      2        \u001b[36m0.7014\u001b[0m  9.1509\n",
      "      3        \u001b[36m0.6955\u001b[0m  9.4485\n",
      "      4        0.6960  9.2246\n",
      "      5        \u001b[36m0.6937\u001b[0m  9.1040\n",
      "      6        0.6948  9.7996\n",
      "      7        0.6944  9.1443\n",
      "      8        0.6938  9.0212\n",
      "      9        \u001b[36m0.6933\u001b[0m  9.1843\n",
      "     10        \u001b[36m0.6912\u001b[0m  9.3199\n",
      "     11        \u001b[36m0.6907\u001b[0m  9.0440\n",
      "     12        0.6915  9.2395\n",
      "     13        0.6936  9.6437\n",
      "     14        0.6908  8.8855\n",
      "     15        \u001b[36m0.6872\u001b[0m  9.3233\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7282\u001b[0m  9.1562\n",
      "      2        \u001b[36m0.6954\u001b[0m  8.8999\n",
      "      3        \u001b[36m0.6946\u001b[0m  9.9868\n",
      "      4        \u001b[36m0.6913\u001b[0m  9.2962\n",
      "      5        \u001b[36m0.6868\u001b[0m  9.0681\n",
      "      6        0.6961  9.1542\n",
      "      7        0.6940  9.1475\n",
      "      8        0.6871  9.3083\n",
      "      9        0.6881  9.4186\n",
      "     10        0.6869  9.7894\n",
      "     11        \u001b[36m0.6846\u001b[0m  9.0563\n",
      "     12        0.6848  8.9224\n",
      "     13        \u001b[36m0.6747\u001b[0m  9.2365\n",
      "     14        0.6851  9.1782\n",
      "     15        0.6902  9.5692\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7168\u001b[0m  8.9903\n",
      "      2        \u001b[36m0.7045\u001b[0m  9.2864\n",
      "      3        \u001b[36m0.6968\u001b[0m  9.2142\n",
      "      4        \u001b[36m0.6917\u001b[0m  9.2272\n",
      "      5        \u001b[36m0.6864\u001b[0m  9.0963\n",
      "      6        \u001b[36m0.6719\u001b[0m  9.9768\n",
      "      7        0.6832  9.1706\n",
      "      8        \u001b[36m0.6682\u001b[0m  8.8188\n",
      "      9        0.6862  9.1432\n",
      "     10        0.6887  9.3390\n",
      "     11        0.6879  9.1026\n",
      "     12        \u001b[36m0.6374\u001b[0m  9.3208\n",
      "     13        0.6566  9.7066\n",
      "     14        \u001b[36m0.6315\u001b[0m  9.1044\n",
      "     15        \u001b[36m0.6076\u001b[0m  8.9788\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.6935\u001b[0m  9.2925\n",
      "      2        0.6988  9.0420\n",
      "      3        0.7113  9.5521\n",
      "      4        0.6963  9.4495\n",
      "      5        \u001b[36m0.6916\u001b[0m  8.9147\n",
      "      6        0.6938  9.0704\n",
      "      7        0.6953  9.2561\n",
      "      8        0.6947  9.3715\n",
      "      9        0.6923  9.2937\n",
      "     10        \u001b[36m0.6910\u001b[0m  9.5158\n",
      "     11        \u001b[36m0.6887\u001b[0m  9.1986\n",
      "     12        0.6935  9.0381\n",
      "     13        0.6909  9.1388\n",
      "     14        \u001b[36m0.6855\u001b[0m  9.0277\n",
      "     15        0.6876  9.4411\n",
      "     16        \u001b[36m0.6790\u001b[0m  9.6214\n",
      "     17        0.6868  9.1190\n",
      "     18        \u001b[36m0.6724\u001b[0m  8.9962\n",
      "     19        0.6847  9.3310\n",
      "     20        0.6803  9.2112\n",
      "     21        0.6958  9.2585\n",
      "     22        0.6798  9.8208\n",
      "     23        0.6859  9.2241\n",
      "     24        0.6748  8.9003\n",
      "     25        0.6782  9.0392\n",
      "     26        0.6843  9.1763\n",
      "     27        0.6869  9.1637\n",
      "     28        0.6733  9.1438\n",
      "     29        0.6842  9.6850\n",
      "     30        0.6763  9.1771\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7414\u001b[0m  9.2614\n",
      "      2        \u001b[36m0.6987\u001b[0m  9.2157\n",
      "      3        \u001b[36m0.6951\u001b[0m  9.2662\n",
      "      4        0.6961  9.2855\n",
      "      5        \u001b[36m0.6938\u001b[0m  9.4883\n",
      "      6        \u001b[36m0.6934\u001b[0m  9.1315\n",
      "      7        0.6937  9.2611\n",
      "      8        \u001b[36m0.6926\u001b[0m  9.1842\n",
      "      9        0.6938  9.1868\n",
      "     10        \u001b[36m0.6898\u001b[0m  9.1496\n",
      "     11        0.6930  9.7829\n",
      "     12        \u001b[36m0.6864\u001b[0m  9.0743\n",
      "     13        0.6870  9.0271\n",
      "     14        \u001b[36m0.6828\u001b[0m  9.1596\n",
      "     15        0.6985  9.1233\n",
      "     16        0.6928  9.2977\n",
      "     17        0.6957  9.2992\n",
      "     18        0.6910  9.5929\n",
      "     19        0.6920  8.9820\n",
      "     20        0.6909  9.2367\n",
      "     21        0.6916  9.1359\n",
      "     22        0.6937  9.2301\n",
      "     23        0.6919  9.5671\n",
      "     24        0.6918  9.7067\n",
      "     25        0.6879  9.1273\n",
      "     26        0.6842  9.0338\n",
      "     27        0.6883  9.1764\n",
      "     28        0.6904  8.9962\n",
      "     29        0.6832  9.0927\n",
      "     30        0.6845  9.5384\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7204\u001b[0m  9.1068\n",
      "      2        \u001b[36m0.6985\u001b[0m  8.9468\n",
      "      3        \u001b[36m0.6980\u001b[0m  9.1301\n",
      "      4        \u001b[36m0.6953\u001b[0m  9.1406\n",
      "      5        0.6964  9.2854\n",
      "      6        \u001b[36m0.6935\u001b[0m  9.8137\n",
      "      7        \u001b[36m0.6933\u001b[0m  9.0056\n",
      "      8        \u001b[36m0.6929\u001b[0m  9.0044\n",
      "      9        \u001b[36m0.6915\u001b[0m  9.4249\n",
      "     10        0.6969  9.1730\n",
      "     11        0.6942  9.0928\n",
      "     12        0.6931  9.6407\n",
      "     13        0.6936  9.4369\n",
      "     14        0.6929  8.9980\n",
      "     15        \u001b[36m0.6914\u001b[0m  9.3024\n",
      "     16        0.6929  9.2465\n",
      "     17        \u001b[36m0.6876\u001b[0m  9.1846\n",
      "     18        \u001b[36m0.6842\u001b[0m  9.1567\n",
      "     19        0.6888  9.6546\n",
      "     20        \u001b[36m0.6787\u001b[0m  9.0664\n",
      "     21        \u001b[36m0.6702\u001b[0m  9.3016\n",
      "     22        0.6786  9.1623\n",
      "     23        \u001b[36m0.6639\u001b[0m  9.2498\n",
      "     24        \u001b[36m0.6458\u001b[0m  9.2615\n",
      "     25        0.6517  9.4274\n",
      "     26        0.6465  9.2293\n",
      "     27        \u001b[36m0.6335\u001b[0m  9.0425\n",
      "     28        0.6454  9.1982\n",
      "     29        0.6544  9.0538\n",
      "     30        \u001b[36m0.6075\u001b[0m  9.2372\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7072\u001b[0m  9.1157\n",
      "      2        \u001b[36m0.6916\u001b[0m  8.9705\n",
      "      3        \u001b[36m0.6877\u001b[0m  8.9277\n",
      "      4        \u001b[36m0.6739\u001b[0m  9.1112\n",
      "      5        0.7039  9.0695\n",
      "      6        0.6900  8.9715\n",
      "      7        0.6939  9.6853\n",
      "      8        0.6949  9.1633\n",
      "      9        0.6869  9.1254\n",
      "     10        0.6887  9.2114\n",
      "     11        0.6861  9.0694\n",
      "     12        \u001b[36m0.6715\u001b[0m  9.0412\n",
      "     13        \u001b[36m0.6531\u001b[0m  9.2504\n",
      "     14        0.6534  9.7312\n",
      "     15        0.6825  8.9709\n",
      "     16        \u001b[36m0.6441\u001b[0m  9.1402\n",
      "     17        0.6454  9.1364\n",
      "     18        0.6964  9.1008\n",
      "     19        0.6641  9.0585\n",
      "     20        \u001b[36m0.6354\u001b[0m  9.7085\n",
      "     21        0.6404  9.2861\n",
      "     22        \u001b[36m0.6058\u001b[0m  9.3726\n",
      "     23        0.6243  9.2260\n",
      "     24        \u001b[36m0.5895\u001b[0m  9.1200\n",
      "     25        0.5899  9.3050\n",
      "     26        \u001b[36m0.5874\u001b[0m  9.2786\n",
      "     27        0.6080  9.5105\n",
      "     28        \u001b[36m0.5360\u001b[0m  9.3282\n",
      "     29        0.5539  9.1683\n",
      "     30        0.6080  9.2270\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m0.7108\u001b[0m  9.6093\n",
      "      2        \u001b[36m0.6997\u001b[0m  9.7712\n",
      "      3        \u001b[36m0.6970\u001b[0m  9.1130\n",
      "      4        \u001b[36m0.6942\u001b[0m  8.9026\n",
      "      5        0.6990  9.3275\n",
      "      6        \u001b[36m0.6942\u001b[0m  9.1001\n",
      "      7        0.6951  9.0587\n",
      "      8        \u001b[36m0.6934\u001b[0m  9.7749\n",
      "      9        0.6934  9.3786\n",
      "     10        0.6934  9.0484\n",
      "     11        \u001b[36m0.6934\u001b[0m  9.2870\n",
      "     12        \u001b[36m0.6915\u001b[0m  9.2488\n",
      "     13        \u001b[36m0.6900\u001b[0m  9.3731\n",
      "     14        0.6956  9.2750\n",
      "     15        0.6935  9.5905\n",
      "     16        0.6907  8.8659\n",
      "     17        0.6939  9.3792\n",
      "     18        0.6914  9.1376\n",
      "     19        \u001b[36m0.6871\u001b[0m  9.3151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     20        \u001b[36m0.6852\u001b[0m  8.9951\n",
      "     21        0.6880  9.7198\n",
      "     22        0.6940  9.3886\n",
      "     23        0.6905  8.8739\n",
      "     24        0.6907  9.2312\n",
      "     25        \u001b[36m0.6799\u001b[0m  9.1437\n",
      "     26        0.6909  9.3119\n",
      "     27        0.6860  9.1472\n",
      "     28        0.6818  9.6215\n",
      "     29        0.6837  9.0803\n",
      "     30        \u001b[36m0.6799\u001b[0m  9.2213\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.4987\u001b[0m  11.0838\n",
      "      2        \u001b[36m0.3135\u001b[0m  11.0287\n",
      "      3        \u001b[36m0.2957\u001b[0m  11.6704\n",
      "      4        \u001b[36m0.1945\u001b[0m  11.0660\n",
      "      5        \u001b[36m0.1760\u001b[0m  11.1328\n",
      "      6        0.2000  11.1845\n",
      "      7        \u001b[36m0.1706\u001b[0m  11.1992\n",
      "      8        \u001b[36m0.1169\u001b[0m  12.2519\n",
      "      9        \u001b[36m0.0726\u001b[0m  10.8894\n",
      "     10        0.1062  10.7788\n",
      "     11        0.0754  10.8158\n",
      "     12        \u001b[36m0.0588\u001b[0m  10.9001\n",
      "     13        0.0711  11.7388\n",
      "     14        0.1068  11.1669\n",
      "     15        0.1150  10.8106\n",
      "     16        \u001b[36m0.0320\u001b[0m  10.8436\n",
      "     17        0.0777  10.6942\n",
      "     18        0.0992  11.2493\n",
      "     19        0.0769  11.5830\n",
      "     20        0.0701  10.8448\n",
      "     21        \u001b[36m0.0280\u001b[0m  10.7556\n",
      "     22        0.0824  10.9882\n",
      "     23        0.0540  10.8394\n",
      "     24        0.0610  11.4602\n",
      "     25        0.1027  11.1966\n",
      "     26        0.0465  10.8038\n",
      "     27        0.0518  10.9650\n",
      "     28        0.0529  11.2114\n",
      "     29        0.0376  11.0778\n",
      "     30        0.0583  11.4281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, str...\n",
       "      (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (act2): ReLU()\n",
       "      (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  ),\n",
       "),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'lr': [1e-05, 0.0001, 0.001], 'max_epochs': [15, 30],\n",
       "                         'optimizer': [<class 'torch.optim.adam.Adam'>],\n",
       "                         'optimizer__weight_decay': [0.001]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Зададим возможные значения параметров сети, выполним обучение\n",
    "params = {'optimizer': [torch.optim.Adam],\n",
    "          'lr': [1.0e-5, 1.0e-4, 1.0e-3],\n",
    "          'optimizer__weight_decay': [1.0e-3],\n",
    "          'max_epochs': [15, 30]}\n",
    "gs = GridSearchCV(net, params, cv=5, scoring='accuracy')\n",
    "# Выполним поиск наилучших параметров сети\n",
    "gs.fit(X_sl, y_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0001,\n",
       " 'max_epochs': 30,\n",
       " 'optimizer': torch.optim.adam.Adam,\n",
       " 'optimizer__weight_decay': 0.001}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выведем наилучшие параметры сети\n",
    "result = gs.best_params_\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([146.00534959, 285.59886847, 145.19197793, 283.95779476,\n",
       "        145.10002098, 283.62053204]),\n",
       " 'std_fit_time': array([0.9976515 , 0.42581014, 0.48622393, 1.25186575, 0.39448992,\n",
       "        0.36345732]),\n",
       " 'mean_score_time': array([3.95416985, 4.11363239, 4.15013285, 4.03192296, 4.02667861,\n",
       "        3.97904644]),\n",
       " 'std_score_time': array([0.10203793, 0.15657464, 0.21766283, 0.15836999, 0.08297086,\n",
       "        0.12829872]),\n",
       " 'param_lr': masked_array(data=[1e-05, 1e-05, 0.0001, 0.0001, 0.001, 0.001],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_epochs': masked_array(data=[15, 30, 15, 30, 15, 30],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_optimizer': masked_array(data=[<class 'torch.optim.adam.Adam'>,\n",
       "                    <class 'torch.optim.adam.Adam'>,\n",
       "                    <class 'torch.optim.adam.Adam'>,\n",
       "                    <class 'torch.optim.adam.Adam'>,\n",
       "                    <class 'torch.optim.adam.Adam'>,\n",
       "                    <class 'torch.optim.adam.Adam'>],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_optimizer__weight_decay': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'lr': 1e-05,\n",
       "   'max_epochs': 15,\n",
       "   'optimizer': torch.optim.adam.Adam,\n",
       "   'optimizer__weight_decay': 0.001},\n",
       "  {'lr': 1e-05,\n",
       "   'max_epochs': 30,\n",
       "   'optimizer': torch.optim.adam.Adam,\n",
       "   'optimizer__weight_decay': 0.001},\n",
       "  {'lr': 0.0001,\n",
       "   'max_epochs': 15,\n",
       "   'optimizer': torch.optim.adam.Adam,\n",
       "   'optimizer__weight_decay': 0.001},\n",
       "  {'lr': 0.0001,\n",
       "   'max_epochs': 30,\n",
       "   'optimizer': torch.optim.adam.Adam,\n",
       "   'optimizer__weight_decay': 0.001},\n",
       "  {'lr': 0.001,\n",
       "   'max_epochs': 15,\n",
       "   'optimizer': torch.optim.adam.Adam,\n",
       "   'optimizer__weight_decay': 0.001},\n",
       "  {'lr': 0.001,\n",
       "   'max_epochs': 30,\n",
       "   'optimizer': torch.optim.adam.Adam,\n",
       "   'optimizer__weight_decay': 0.001}],\n",
       " 'split0_test_score': array([0.953125, 1.      , 1.      , 1.      , 0.6875  , 0.59375 ]),\n",
       " 'split1_test_score': array([0.96875 , 0.953125, 1.      , 1.      , 0.5625  , 0.65625 ]),\n",
       " 'split2_test_score': array([0.96875 , 0.984375, 0.984375, 1.      , 0.609375, 0.640625]),\n",
       " 'split3_test_score': array([0.96875 , 1.      , 1.      , 0.984375, 0.640625, 0.890625]),\n",
       " 'split4_test_score': array([1.      , 0.96875 , 0.984375, 1.      , 0.71875 , 0.640625]),\n",
       " 'mean_test_score': array([0.971875, 0.98125 , 0.99375 , 0.996875, 0.64375 , 0.684375]),\n",
       " 'std_test_score': array([0.01530931, 0.01822172, 0.00765466, 0.00625   , 0.05537514,\n",
       "        0.10523411]),\n",
       " 'rank_test_score': array([4, 3, 2, 1, 6, 5], dtype=int32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test/unknown'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выполним копирование изображений в папку unknown\n",
    "# это необходимо, чтобы задать метку класса\n",
    "test_dir = 'test'\n",
    "shutil.copytree(os.path.join(data_root, 'test'), \n",
    "                os.path.join(test_dir, 'unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополним специальный метод __getitem__ возвратом пути к изображению\n",
    "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "    \n",
    "test_dataset = ImageFolderWithPaths('/kaggle/working/test', test_transforms)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:08<00:00, 10.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# Выполним классификацию тестового набора данных\n",
    "test_predictions = []\n",
    "test_img_paths = []\n",
    "\n",
    "model = gs.best_estimator_\n",
    "sm = torch.nn.Softmax(dim=1)\n",
    "\n",
    "for inputs, labels, paths in tqdm(test_dataloader):\n",
    "    inputs = inputs\n",
    "    labels = labels\n",
    "    preds = model.predict_proba(inputs)\n",
    "    test_predictions.extend(preds)\n",
    "    test_img_paths.extend(paths)\n",
    "test_predictions = torch.tensor(test_predictions)\n",
    "test_predictions = sm(test_predictions)\n",
    "test_predictions = test_predictions[:, 1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001</th>\n",
       "      <td>dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002</th>\n",
       "      <td>dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003</th>\n",
       "      <td>dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004</th>\n",
       "      <td>cleaned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0005</th>\n",
       "      <td>dirty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label\n",
       "id           \n",
       "0000    dirty\n",
       "0001    dirty\n",
       "0002    dirty\n",
       "0003    dirty\n",
       "0004  cleaned\n",
       "0005    dirty"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим и заполним датафрейм с результатами\n",
    "submission_df = pd.DataFrame.from_dict({'id': test_img_paths, 'label': test_predictions})\n",
    "submission_df['label'] = submission_df['label'].map(lambda pred: 'dirty' if pred > 0.7 else 'cleaned')\n",
    "submission_df['id'] = submission_df['id'].str.replace('/kaggle/working/test/unknown/', '')\n",
    "submission_df['id'] = submission_df['id'].str.replace('.jpg', '')\n",
    "submission_df.set_index('id', inplace=True)\n",
    "submission_df.head(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем датафрейм в csv файл\n",
    "submission_df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очистим файловое пространство от ненужных данных\n",
    "!rm -rf train test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
